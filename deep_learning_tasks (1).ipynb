{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90eac9fb",
      "metadata": {
        "id": "90eac9fb"
      },
      "source": [
        "# ğŸ“˜ Deep Neural Network Modeling Tasks using TensorFlow/Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d80aa332",
      "metadata": {
        "id": "d80aa332"
      },
      "source": [
        "## âœ… Task 1: Basic Neural Network on MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0744862d",
      "metadata": {
        "id": "0744862d"
      },
      "source": [
        "\n",
        "**Goal**: Understand basic DNN structure using dense layers and softmax.\n",
        "- Load MNIST dataset\n",
        "- Flatten and normalize input images\n",
        "- Use Dense + Softmax layers\n",
        "- Train and evaluate model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c9f9d430",
      "metadata": {
        "id": "c9f9d430",
        "outputId": "e3e53366-fca4-4b02-f0ba-0349252f0085",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8585 - loss: 0.4903\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9558 - loss: 0.1542\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9687 - loss: 0.1098\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.0838\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9796 - loss: 0.0675\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "x_train = x_train.reshape(-1, 28*28)\n",
        "x_test = x_test.reshape(-1, 28*28)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "# Save MNIST model here\n",
        "model.save('mnist_dnn_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa55cd96",
      "metadata": {
        "id": "aa55cd96"
      },
      "source": [
        "## âœ… Task 2: Add More Hidden Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d051ea3",
      "metadata": {
        "id": "9d051ea3"
      },
      "source": [
        "\n",
        "**Goal**: Add more layers to increase depth and learn complex patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ce8c21ba",
      "metadata": {
        "id": "ce8c21ba",
        "outputId": "db8b4daf-fa72-46df-8347-ae364f11feeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.4555\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9665 - loss: 0.1098\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9764 - loss: 0.0736\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0550\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.0441\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9729 - loss: 0.0977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0901135727763176, 0.9750000238418579]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "# (Optional) save if you want\n",
        "# model.save('mnist_dnn_deeper_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "281381ed",
      "metadata": {
        "id": "281381ed"
      },
      "source": [
        "## âœ… Task 3: Use Dropout for Regularization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a3c056",
      "metadata": {
        "id": "66a3c056"
      },
      "source": [
        "\n",
        "**Goal**: Use dropout layers to prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f69c324e",
      "metadata": {
        "id": "f69c324e",
        "outputId": "707fd7cb-70c3-42a4-c918-71601fb85094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.6537 - val_accuracy: 0.9526 - val_loss: 0.1602\n",
            "Epoch 2/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9320 - loss: 0.2255 - val_accuracy: 0.9665 - val_loss: 0.1142\n",
            "Epoch 3/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9455 - loss: 0.1810 - val_accuracy: 0.9693 - val_loss: 0.0986\n",
            "Epoch 4/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1568 - val_accuracy: 0.9686 - val_loss: 0.1036\n",
            "Epoch 5/5\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9591 - loss: 0.1379 - val_accuracy: 0.9752 - val_loss: 0.0867\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.0957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=(784,)),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, epochs=5, validation_split=0.2)\n",
        "model.evaluate(x_test, y_test)\n",
        "\n",
        "# Save dropout model here\n",
        "model.save('mnist_dnn_dropout_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0393091",
      "metadata": {
        "id": "b0393091"
      },
      "source": [
        "## âœ… Task 4: Build a CNN on CIFAR-10 Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32fefd4b",
      "metadata": {
        "id": "32fefd4b"
      },
      "source": [
        "\n",
        "**Goal**: Use convolutional and pooling layers for image classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1caee12c",
      "metadata": {
        "id": "1caee12c",
        "outputId": "525f81ed-f8b5-4fde-fff8-e4bf14c543ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 37ms/step - accuracy: 0.3546 - loss: 1.7562 - val_accuracy: 0.5452 - val_loss: 1.2603\n",
            "Epoch 2/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 37ms/step - accuracy: 0.5802 - loss: 1.1941 - val_accuracy: 0.6324 - val_loss: 1.0826\n",
            "Epoch 3/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 36ms/step - accuracy: 0.6417 - loss: 1.0377 - val_accuracy: 0.6618 - val_loss: 0.9888\n",
            "Epoch 4/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 36ms/step - accuracy: 0.6690 - loss: 0.9479 - val_accuracy: 0.6758 - val_loss: 0.9384\n",
            "Epoch 5/5\n",
            "\u001b[1m1407/1407\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 36ms/step - accuracy: 0.7001 - loss: 0.8694 - val_accuracy: 0.6876 - val_loss: 0.9326\n",
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6747 - loss: 0.9572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "cnn_model = models.Sequential([\n",
        "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(32,32,3)),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.fit(x_train, y_train, epochs=5, validation_split=0.1)\n",
        "cnn_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Save CIFAR-10 CNN model (both names)\n",
        "cnn_model.save('cifar10_cnn_model.h5')\n",
        "cnn_model.save('cnn_model.h5')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3532f92f",
      "metadata": {
        "id": "3532f92f"
      },
      "source": [
        "## âœ… Task 5: Save and Reload a Trained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b76867ba",
      "metadata": {
        "id": "b76867ba"
      },
      "source": [
        "\n",
        "**Goal**: Learn to save and reuse models without retraining.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "88258717",
      "metadata": {
        "id": "88258717",
        "outputId": "31dc6bd4-b0e6-4e5b-8397-8f1365189bc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6747 - loss: 0.9572\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9639534950256348, 0.6732000112533569]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load and evaluate from 'cnn_model.h5' (or 'cifar10_cnn_model.h5')\n",
        "reloaded_model = tf.keras.models.load_model('cnn_model.h5')\n",
        "reloaded_model.evaluate(x_test, y_test)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}